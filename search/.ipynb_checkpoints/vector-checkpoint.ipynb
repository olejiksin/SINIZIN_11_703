{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southern-lawyer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\oleji\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter query pls (ex: cancel)\n",
      "print 'exit' to close kernel\n",
      "яндекс почта онлайн\n",
      "Docs list: выкачка77.txt, выкачка1.txt, выкачка38.txt\n",
      "\n",
      "Enter query pls (ex: cancel)\n",
      "print 'exit' to close kernel\n",
      "exit\n",
      "No documents\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords as s\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = set(s.words('english'))\n",
    "stopwords = set(s.words('russian'))\n",
    "docdir = \"./выкачка/\"\n",
    "docnames = [a for a in os.listdir(docdir)]\n",
    "\n",
    "def loadDocs(docs):\n",
    "    data = [(open( docdir + a, encoding='utf-8').read()).lower() for a in docs]\n",
    "    data = [list(filter(lambda a: not a in stopwords and a != '', a.split(\" \"))) for a in data]\n",
    "    return data\n",
    "\n",
    "def tfidf(corpus, index, term):\n",
    "    tf = count(corpus[index], term) / len(corpus[index])\n",
    "    num_docs_with_term = len([b for b in corpus if term in b])\n",
    "    if num_docs_with_term == 0: idf = 0\n",
    "    else:\n",
    "        df = len(corpus) / num_docs_with_term\n",
    "        idf = math.log(df) if df > 1 else 1\n",
    "    return math.cos(tf * idf) if tf > 0 and idf > 0 else 0\n",
    "\n",
    "def count(arr,item):\n",
    "    return len([e for e in arr if e == item])\n",
    "\n",
    "def printResults(arr,stem):\n",
    "    c = sorted(enumerate(arr), key=lambda t: float(t[1]), reverse=0)\n",
    "    b = [t for t in c if not float(t[1]) == 0]\n",
    "    if len(b) < 3: l = len(b)\n",
    "    else: l = 3\n",
    "    if l > 0: print(\"Docs list: \"+\", \".join([docnames[i] for i, _ in b[:l]]))\n",
    "    else:\n",
    "        print(\"No documents\")\n",
    "    if stem:\n",
    "        print(\"ALARM! STEM WORDS\")\n",
    "    print()\n",
    "\n",
    "docs = loadDocs(docnames)\n",
    "\n",
    "flag=True\n",
    "\n",
    "while(flag):\n",
    "    print(\"Enter query pls (ex: cancel)\")\n",
    "    sys.stdout.write(\"print 'exit' to close kernel\\n\")\n",
    "    words = input().split(\" \")\n",
    "    if len(words) == 1 and words[0] == 'exit': \n",
    "        exit()\n",
    "        flag=False\n",
    "    queryAvgs = []\n",
    "    stem = False\n",
    "    for i in range(0, len(docs)):\n",
    "        tot = float(0)\n",
    "        for word in words:\n",
    "            if not stem: \n",
    "                stem = word in stopwords \n",
    "            tot += tfidf(docs,i,word)\n",
    "        queryAvgs.append(tot/len(words))\n",
    "    printResults(queryAvgs,stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-gather",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-deployment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
