{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "refined-stylus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\oleji\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter query pls (ex: cancel)\n",
      "print 'exit' to close kernel\n",
      "яндекс\n",
      "kekk\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'яндекс'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\oleji\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'яндекс'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-e0114e030636>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mflag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-50-e0114e030636>\u001b[0m in \u001b[0;36msearch\u001b[1;34m(queryy)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             \u001b[0mvectors_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_idf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m     \u001b[0mvectorList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'document'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'term'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tf-idf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[0mvectorList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'document'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'term'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tf-idf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oleji\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oleji\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oleji\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'яндекс'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import sys\n",
    "import collections\n",
    "import nltk\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords as s\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = s.words('english')\n",
    "stopwords.extend(s.words('russian'))\n",
    "\n",
    "def compute_idf(word, text):\n",
    "    return math.log10(len(text)/sum([1.0 for i in text if word in i]))\n",
    "\n",
    "def compute_tf(word,text):\n",
    "    tf_text = collections.Counter(text)\n",
    "    for i in tf_text:\n",
    "        tf_text[i] = tf_text[i]/float(len(text))\n",
    "    if tf_text[word] is None:\n",
    "        tf_text[word]=0\n",
    "    return tf_text[word]\n",
    "\n",
    "def countTfIdf(word):\n",
    "    tfidf=0\n",
    "    tfSet={}\n",
    "    megaList=list()\n",
    "    for i in range (0,10):\n",
    "        listt=list()\n",
    "        with open('C:/Users/oleji/Desktop/topkek/search/выкачка/выкачка'+str(i)+'.txt', encoding='utf-8') as file:\n",
    "            k=[row.strip().split() for row in file]\n",
    "            for l in range(0,len(k[0])):\n",
    "                listt.append(k[0][l].lower())\n",
    "            megaList.append(listt)\n",
    "            for doc in listt:\n",
    "                if tfSet.get(word) is None:\n",
    "                    tfSet[word]=[compute_tf(word,listt)]\n",
    "                else:\n",
    "                    tfSet[word].append(compute_tf(word,listt))\n",
    "    \n",
    "    for k,v in tfSet.items():\n",
    "        idf=compute_idf(k,megaList)\n",
    "        for tf in v:\n",
    "            tfidf+=tf*idf\n",
    "\n",
    "def get_idf():\n",
    "    data = {}\n",
    "    with open('C:/Users/oleji/Desktop/topkek/search/tf_tfidf.txt') as file:\n",
    "        file_text = csv.reader(file, delimiter=\"\\n\")\n",
    "        lines = list(file_text)[1:]\n",
    "        for l in lines:\n",
    "            data[l[0].split()[0]] = float(l[0].split()[1])\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_tfidf():\n",
    "    data = {}\n",
    "    with open('C:/Users/oleji/Desktop/topkek/search/tf_tfidf.txt') as file:\n",
    "        file_text = csv.reader(file, delimiter=\"\\n\")\n",
    "        lines = list(file_text)[1:]\n",
    "        for l in lines:\n",
    "            data[l[0].split()[0]] = float(l[0].split()[2])\n",
    "    return data\n",
    "\n",
    "def createIndex():\n",
    "    woordIndex={}\n",
    "    for i in range (0,10):\n",
    "        with open('C:/Users/oleji/Desktop/topkek/search/выкачка/выкачка'+str(i)+'.txt', encoding='utf-8') as file:\n",
    "            k=[row.strip().split() for row in file]\n",
    "            lowSt=[]\n",
    "            for l in range(0,len(k[0])):\n",
    "                lowSt.append(k[0][l].lower())\n",
    "            for l in lowSt:\n",
    "                if woordIndex.get(l) is None:\n",
    "                    woordIndex[l]=[i]\n",
    "                if(i not in woordIndex[l]):\n",
    "                    woordIndex[l].append(i)\n",
    "    return woordIndex\n",
    "                \n",
    "def search(queryy):\n",
    "    lines=[]\n",
    "    with open('C:/Users/oleji/Desktop/topkek/search/tf_tfidf.txt') as file:\n",
    "        lines = [row.strip().split() for row in file]\n",
    "    data=[]\n",
    "    for i in range(0, 10):\n",
    "        with open('C:/Users/oleji/Desktop/topkek/search/выкачка/выкачка'+str(i)+'.txt', encoding='utf-8') as file:\n",
    "            k=[row.strip().split() for row in file]\n",
    "            lowSt=[]\n",
    "            for lo in range(0,len(k[0])):\n",
    "                lowSt.append(k[0][lo].lower())\n",
    "            for l in lines:\n",
    "                if l[0] in lowSt:\n",
    "                    data.extend([('выкачка'+str(i), l[0], l[2])])\n",
    "\n",
    "    tf_idf = pd.DataFrame(data, columns=['document', 'word', 'tf-idf'])\n",
    "#     tf_idf['tf-idf']=tf_idf['tf-idf'].astype(float)\n",
    "#     tf_idf = tf_idf.pivot_table('document', 'word', 'tf-idf')\n",
    "\n",
    "    tokens = []\n",
    "    for w in queryy.split(' '):\n",
    "        tokens.append(w.lower())\n",
    "    t = tokens\n",
    "    index=createIndex()\n",
    "    docs = []\n",
    "    for t in tokens:\n",
    "        if t in index.keys():\n",
    "            docs.append((t, index[t]))\n",
    "    vectors_data = []\n",
    "    for d in docs:\n",
    "        t = d[0]\n",
    "        for i in range(0, 10):\n",
    "            vectors_data.append((i, t, tf_idf.iloc[i][t]))\n",
    "    vectorList = pd.DataFrame(vectors_data, columns=['document', 'term', 'tf-idf'])\n",
    "    vectorList = vectorList.pivot_table('document', 'term', 'tf-idf')\n",
    "    vectorList = vectorList.fillna(0)\n",
    "    \n",
    "    tf_idf_query = {}\n",
    "    for word in tokens:\n",
    "        tf_idf_query[word] = countTfIdf(word)\n",
    "    vectorList = vectorList.append(tf_idf_query,ignore_index=True)\n",
    "    print(vectorList.values[0])\n",
    "    cosine = cosine_similarity([vectorList.values[10]], vectorList.values[0:10])\n",
    "    cosine = cosine.tolist()[0]\n",
    "    doc_list = sorted(range(len(cosine_similarity)), key=lambda k: cosine[k])\n",
    "#     links = {}\n",
    "#     with open('C:/Users/oleji/Desktop/topkek/search/index.txt', encoding='utf-8') as file:\n",
    "#         file = csv.reader(file, delimiter=\"\\n\")\n",
    "#         lines = list(file)\n",
    "#         for l in lines:\n",
    "#             num = l.split()[0]\n",
    "#             links[int(num)] = l.split()[1]\n",
    "    for i in reversed(doc_list):\n",
    "        print('выкачка'+str(i), cosine[i])\n",
    "\n",
    "flag=True\n",
    "while(flag):\n",
    "    print(\"Enter query pls (ex: cancel)\")\n",
    "    sys.stdout.write(\"print 'exit' to close kernel\\n\")\n",
    "    words = input()\n",
    "    if len(words) == 1 and words[0] == 'exit': \n",
    "        exit()\n",
    "        flag=False\n",
    "    search(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-blowing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
